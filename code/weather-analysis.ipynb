{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Weather Analysis\n",
    "## Project 1 - Group3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "The stadium, team, and gameday location data are gathered from the \"NFL scores and betting data\" Kaggle dataset:\n",
    "https://www.kaggle.com/tobycrabtree/nfl-scores-and-betting-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_ImportDataToFrames(arg_dictDataFiles, arg_strEnconding = \"UTF-8\"):\n",
    "    '''\n",
    "    FUNCTION: fn_ImportDataForWeatherAnalysis\n",
    "    \n",
    "    DESCRIPTION: Reads csv data from dictionary and populated into dictionary of dataframes\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        arg_dictDataFiles:  Dictionary containing strings pointing to csv input files\n",
    "        arg_strEncoding:    String specifying encoding used in files\n",
    "        \n",
    "    RETURNS:\n",
    "        Dictionary matching length and keys of arg_dictDataFiles but with populated dataframes\n",
    "        instead of filename strings\n",
    "    '''    \n",
    "    \n",
    "    # define dictionary to be returned\n",
    "    local_dictDataFrames = {}\n",
    "    \n",
    "    # read each of the files from the dictionary arg into a dataframe\n",
    "    for key in arg_dictDataFiles.keys():\n",
    "        local_dictDataFrames[key] = pd.read_csv(arg_dictDataFiles[key], encoding = arg_strEnconding)\n",
    "\n",
    "    return local_dictDataFrames\n",
    "\n",
    "# define filename strings where csv data resides\n",
    "dict_DataFiles = {\n",
    "    \"Stadiums\": \"../data/nfl_stadiums.csv\",\n",
    "    \"Teams\": \"../data/nfl_teams.csv\",\n",
    "    \"Games\": \"../data/spreadspoke_scores.csv\"\n",
    "}\n",
    "\n",
    "# populate dataframes with csv data from files\n",
    "dict_DataFrames = fn_ImportDataToFrames(dict_DataFiles, \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Datasets to Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_ReduceData(arg_dictDataFrames, arg_dictColsToDrop, arg_dictRowCriteria):\n",
    "    '''\n",
    "    FUNCTION: fn_ReduceData\n",
    "    \n",
    "    DESCRIPTION: Reduces dataframes by dropping specified columns and only keeping specified rows\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        arg_dictDataFrames: Dictionary containing dataframes to be reduced\n",
    "        arg_dictColsToDrop: Dictionary containing lists of columns to be dropped for each dataframe\n",
    "        arg_dictRowCriteria: Dictionary containing lists of booleans indicating which rows to keep\n",
    "        \n",
    "    RETURNS:\n",
    "        Dictionary matching length of arg_dictDataFrames but with reduced shape\n",
    "    '''    \n",
    "    \n",
    "    # define dictionary to be returned\n",
    "    local_dictDataFrames = {}\n",
    "\n",
    "\n",
    "    # iterate through dataframes removing columns and filtering rows\n",
    "    for key in arg_dictDataFrames.keys():\n",
    "        \n",
    "        # get cols to remove\n",
    "        list_cols = arg_dictColsToDrop[key]\n",
    "        \n",
    "        # get row filter criteria\n",
    "        list_criteria = arg_dictRowCriteria[key]\n",
    "        \n",
    "        # reduce dataframe columns\n",
    "        local_dictDataFrames[key] = arg_dictDataFrames[key].drop(list_cols, axis=1)\n",
    "        \n",
    "        # reduce dataframe rows\n",
    "        local_dictDataFrames[key] = local_dictDataFrames[key][list_criteria]\n",
    "        \n",
    "    return local_dictDataFrames\n",
    "\n",
    "# define lists of columns to be dropped from each dataframe\n",
    "dict_ColsToDrop = {\n",
    "    \"Stadiums\": [\"stadium_location\", \"stadium_open\",\"stadium_close\",\"stadium_address\",\\\n",
    "                           \"stadium_weather_type\",\"stadium_capacity\",\"stadium_surface\",\"NAME\",\"ELEVATION\"],\n",
    "    \"Teams\": [\"team_name_short\",\"team_id_pfr\",\"team_conference\",\"team_division\",\"team_conference_pre2002\",\\\n",
    "                        \"team_division_pre2002\"],\n",
    "    \"Games\": [\"schedule_week\",\"team_favorite_id\",\"spread_favorite\",\"over_under_line\",\"stadium_neutral\"]\n",
    "}\n",
    "\n",
    "# setup boolean criteria to identify rows within our analysis years (2009-2018)\n",
    "dict_FilterCriteria = {\n",
    "    \"Stadiums\": [],\n",
    "    \"Teams\": [],\n",
    "    \"Games\": (dict_DataFrames[\"Games\"][\"schedule_season\"]>=2009) & (dict_DataFrames[\"Games\"][\"schedule_season\"]<=2018)\n",
    "}\n",
    "\n",
    "# reduce dataframe columns and rows\n",
    "dict_DataFrames = fn_ReduceData(dict_DataFrames, dict_ColsToDrop, dict_FilterCriteria)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add Team Ids to game data by merging team and game frames on team name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on home team first\n",
    "df_Games = df_Games.merge(df_Teams, how=\"left\", left_on=\"team_home\", right_on=\"team_name\")\n",
    "\n",
    "# rename new ID column to indicate it is home team\n",
    "df_Games.rename({\"team_id\":\"team_id_home\"},axis=1,inplace=True)\n",
    "\n",
    "# merge on away team next\n",
    "df_Games = df_Games.merge(df_Teams, how=\"left\", left_on=\"team_away\", right_on=\"team_name\")\n",
    "\n",
    "# rename new ID column to indicate it is home team\n",
    "df_Games.rename({\"team_id\":\"team_id_away\"},axis=1,inplace=True)\n",
    "\n",
    "# cleanup unnecessary columns\n",
    "df_Games.drop([\"team_name_y\",\"team_name_x\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add Weather Station Code, Lat, and Long by merging stadium and game frames on stadium name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on stadium name\n",
    "df_Games = df_Games.merge(df_Stadiums, how=\"left\", left_on=\"stadium\", right_on=\"stadium_name\")\n",
    "\n",
    "# cleanup unnecessary columns\n",
    "df_Games.drop([\"stadium_name\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py (Project1)",
   "language": "python",
   "name": "project1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
